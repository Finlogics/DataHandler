we want to download stock price data (historica and live) according to orders.json file. the granularity of data can be fine-grained (1M,1S) or coarse (1D). the provider 
is ibkr and we need to download from it. you should choose an api which can download both historical and live data. we do not implement live data for now. the project 
should download data into csv files. if the file is already downloaded and is completed and not corrupted, it should not be downloaded again. for granular data (1S or 1M), 
there is a  csv file for each day. for coarse data (1D), each csv is related for 1 year. for folder structure, there is a folder called data-raw. let me give and example. 
the path to 1D data for AAPL for year 2023 is raw-data/1D/AAPL-2023.csv and the path to MSFT for 2024-05-03 with 1M granularity is raw-data/1M/MSFT-2024-05-03.csv.

There is a file in raw-data folder named normaliziation.json. for each ticker, it should have one itemper granulaity (1M,1S, etc). at startup, its contents should be loaded 
as an object in memory. every time the object in memory is changed, the json file should be updated. every time a major (1D, 5D, and above) garnularity data is fetched from 
ib gateway, the program should check if there is an entry for the combination of (ticker, granularity) in the object; for example (AAPL, 1D). if there is not an entry, 
it should be created by the first entry of the fetched data and saved to json. the idea is to know what is the abouts of values. the value items are these items: 1) open 
2) volume 3) barcount. there are two entries as example in normalization.json.